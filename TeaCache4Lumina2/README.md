<!-- ## **TeaCache4LuminaT2X** -->
# TeaCache4LuminaT2X

[TeaCache](https://github.com/LiewFeng/TeaCache) can speedup [Lumina-Image-2.0](https://github.com/Alpha-VLLM/Lumina-Image-2.0) 2x without much visual quality degradation, in a training-free manner. The following image shows the results generated by TeaCache-Lumina-Image-2.0 with various rel_l1_thresh values: 0 (original), 0.1 (1.05x speedup), 0.2 (1.15x speedup), 0.3 (1.25x speedup).

<p align="center">
    <img src="https://private-user-images.githubusercontent.com/179383288/447037531-1b80195e-57a4-4f8c-a081-9870a1793d09.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDgxNjU3NTgsIm5iZiI6MTc0ODE2NTQ1OCwicGF0aCI6Ii8xNzkzODMyODgvNDQ3MDM3NTMxLTFiODAxOTVlLTU3YTQtNGY4Yy1hMDgxLTk4NzBhMTc5M2QwOS5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyNVQwOTMwNThaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1iNzU3ODQyNDY2OTQxMzJiMjVkMjVhMGMzOTk3MGY5MTQwYzdkNTI1NGQzNTcwZTU5YjQ4NTY2NWY0NTI1ZjZmJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.3WarqdpZ9mLUJynP4a0IpB6aPCIojPku0d2ClvdgOrA" width="150" style="margin: 5px;">
    <img src="https://private-user-images.githubusercontent.com/179383288/447037765-9491dee3-9cb7-4807-8153-7cfaec8582f0.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDgxNjU3NTgsIm5iZiI6MTc0ODE2NTQ1OCwicGF0aCI6Ii8xNzkzODMyODgvNDQ3MDM3NzY1LTk0OTFkZWUzLTljYjctNDgwNy04MTUzLTdjZmFlYzg1ODJmMC5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyNVQwOTMwNThaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0zNjcxZjBhOWZmMzdkNDE1N2EwMjNiNmI3NWQyZTlmYTdjZmY2NTA1YTcwNmFjOTE2ZmQ0NDdlNjcwNmJhZmY5JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.g5LF6WCXqMzSgMtq1IlLxZiJuzGPtQErzik969D9r84" width="150" style="margin: 5px;">
    <img src="https://private-user-images.githubusercontent.com/179383288/447037881-fcd39c74-ecb2-4e99-ab63-8a6325536193.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDgxNjU3NTgsIm5iZiI6MTc0ODE2NTQ1OCwicGF0aCI6Ii8xNzkzODMyODgvNDQ3MDM3ODgxLWZjZDM5Yzc0LWVjYjItNGU5OS1hYjYzLThhNjMyNTUzNjE5My5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyNVQwOTMwNThaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1kYTU2MjQwMDMzOGZjYmNhNmY4MWU2YjBlY2M3MDc5ODAwMDQ3ODdjNTlhZDc5MThiN2Q1OGZlMTdhYjAzZDAyJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.lME_Lu6NvY8Ju56yr9wxxH9UOSrhfleQA_DmSkwKk5Y" width="150" style="margin: 5px;">
    <img src="https://private-user-images.githubusercontent.com/179383288/447037987-ca788c20-a03a-4660-a646-3f454bf4b19f.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDgxNjU3NTgsIm5iZiI6MTc0ODE2NTQ1OCwicGF0aCI6Ii8xNzkzODMyODgvNDQ3MDM3OTg3LWNhNzg4YzIwLWEwM2EtNDY2MC1hNjQ2LTNmNDU0YmY0YjE5Zi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwNTI1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDUyNVQwOTMwNThaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mOGM5YmEyN2NhMGE0MzZiMjU4MWVkZjYzMTdkNTdmM2E1MTBmYTE5MTgzZmM2ZTQ1YWZlYTc1ZjRiYWNhN2ZjJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9._AN5xub4BCEBCE-DPvxyrVZX7ssg-a5nq7ayg0xiPRs" width="150" style="margin: 5px;">
</p>

## ðŸ“ˆ Inference Latency Comparisons on a 4070 laptop(size 1024 x 1536)


|      Lumina-Image-2.0       |         TeaCache (0.1)        |    TeaCache (0.2)    |     TeaCache (0.3)    |
|:---------------------------:|:-----------------------------:|:--------------------:|:---------------------:|
|         ~97.74s             |        ~93.19s                |     ~84.72s            |       ~78.43s             |

## Installation

```shell
pip install --upgrade diffusers[torch] transformers protobuf tokenizers sentencepiece
pip install flash-attn --no-build-isolation
```

## Usage

You can modify the thresh in line 113 to obtain your desired trade-off between latency and visul quality. For single-gpu inference, you can use the following command:

```bash
python teacache_lumina2.py
```

## Citation
If you find TeaCache is useful in your research or applications, please consider giving us a star ðŸŒŸ and citing it by the following BibTeX entry.

```
@article{liu2024timestep,
  title={Timestep Embedding Tells: It's Time to Cache for Video Diffusion Model},
  author={Liu, Feng and Zhang, Shiwei and Wang, Xiaofeng and Wei, Yujie and Qiu, Haonan and Zhao, Yuzhong and Zhang, Yingya and Ye, Qixiang and Wan, Fang},
  journal={arXiv preprint arXiv:2411.19108},
  year={2024}
}
```

## Acknowledgements

We would like to thank the contributors to the [Lumina-Image-2.0](https://github.com/Alpha-VLLM/Lumina-Image-2.0) and [Diffusers](https://github.com/huggingface/diffusers).
